{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee7efd9a-618b-4abd-8789-e639322e693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in c:\\users\\user\\anaconda3\\lib\\site-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade mysql-connector-python\n",
    "# !pip install sshtunnel\n",
    "# !pip install pymysql\n",
    "# !pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "581ea639-bb4e-4d61-b747-c8b17d51e70d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(2013, 'Lost connection to MySQL server during query ([WinError 10054] 현재 연결은 원격 호스트에 의해 강제로 끊겼습니다)')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:782\u001b[0m, in \u001b[0;36mConnection._read_bytes\u001b[1;34m(self, num_bytes)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 782\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rfile\u001b[38;5;241m.\u001b[39mread(num_bytes)\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] 현재 연결은 원격 호스트에 의해 강제로 끊겼습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# DB 연결 설정 (본인의 DB 정보로 수정)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m conn \u001b[38;5;241m=\u001b[39m pymysql\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[0;32m      9\u001b[0m     host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     user\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdbuser\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1234\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m     db\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m     charset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 데이터 가져오기\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:361\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, user, password, host, database, unix_socket, port, charset, collation, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_disabled, ssl_key, ssl_key_password, ssl_verify_cert, ssl_verify_identity, compress, named_pipe, passwd, db)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:668\u001b[0m, in \u001b[0;36mConnection.connect\u001b[1;34m(self, sock)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rfile \u001b[38;5;241m=\u001b[39m sock\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_seq_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 668\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_server_information()\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_authentication()\n\u001b[0;32m    671\u001b[0m \u001b[38;5;66;03m# Send \"SET NAMES\" query on init for:\u001b[39;00m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;66;03m# - Ensure charaset (and collation) is set to the server.\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;66;03m#   - collation_id in handshake packet may be ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;66;03m# - https://github.com/wagtail/wagtail/issues/9477\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;66;03m# - https://zenn.dev/methane/articles/2023-mysql-collation (Japanese)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:1098\u001b[0m, in \u001b[0;36mConnection._get_server_information\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_server_information\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1097\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1098\u001b[0m     packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_packet()\n\u001b[0;32m   1099\u001b[0m     data \u001b[38;5;241m=\u001b[39m packet\u001b[38;5;241m.\u001b[39mget_all_data()\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol_version \u001b[38;5;241m=\u001b[39m data[i]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:744\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    742\u001b[0m buff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m()\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     packet_header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_bytes(\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;66;03m# if DEBUG: dump_packet(packet_header)\u001b[39;00m\n\u001b[0;32m    747\u001b[0m     btrl, btrh, packet_number \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<HBB\u001b[39m\u001b[38;5;124m\"\u001b[39m, packet_header)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:788\u001b[0m, in \u001b[0;36mConnection._read_bytes\u001b[1;34m(self, num_bytes)\u001b[0m\n\u001b[0;32m    786\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_force_close()\n\u001b[1;32m--> 788\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\u001b[38;5;241m.\u001b[39mOperationalError(\n\u001b[0;32m    789\u001b[0m         CR\u001b[38;5;241m.\u001b[39mCR_SERVER_LOST,\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLost connection to MySQL server during query (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    791\u001b[0m     )\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;66;03m# Don't convert unknown exception to MySQLError.\u001b[39;00m\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_force_close()\n",
      "\u001b[1;31mOperationalError\u001b[0m: (2013, 'Lost connection to MySQL server during query ([WinError 10054] 현재 연결은 원격 호스트에 의해 강제로 끊겼습니다)')"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# DB 연결 설정 (본인의 DB 정보로 수정)\n",
    "conn = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='dbuser',\n",
    "    password='1234',\n",
    "    db='project',\n",
    "    charset='utf8'\n",
    ")\n",
    "\n",
    "# 데이터 가져오기\n",
    "try:\n",
    "    query = 'SELECT * FROM NAJU_WEATHER_TB'  # NAJU_WEATHER_TB 테이블에서 데이터 전체를 가져옴\n",
    "    data = pd.read_sql(query, conn)\n",
    "finally:\n",
    "    conn.close()\n",
    "\n",
    "# 시간 정보 처리\n",
    "data['MEAS_DT'] = pd.to_datetime(data['MEAS_DT'])\n",
    "data = data.sort_values('MEAS_DT')\n",
    "\n",
    "# 내일 및 모레 타겟 생성\n",
    "data['AP_tomorrow'] = data['AP'].shift(-24)\n",
    "data['TEMP_tomorrow'] = data['TEMP'].shift(-24)\n",
    "data['HUM_tomorrow'] = data['HUM'].shift(-24)\n",
    "data['WS_tomorrow'] = data['WS'].shift(-24)\n",
    "data['WD_tomorrow'] = data['WD'].shift(-24)\n",
    "data['RF_tomorrow'] = data['RF'].shift(-24)\n",
    "\n",
    "data['AP_day_after'] = data['AP'].shift(-48)\n",
    "data['TEMP_day_after'] = data['TEMP'].shift(-48)\n",
    "data['HUM_day_after'] = data['HUM'].shift(-48)\n",
    "data['WS_day_after'] = data['WS'].shift(-48)\n",
    "data['WD_day_after'] = data['WD'].shift(-48)\n",
    "data['RF_day_after'] = data['RF'].shift(-48)\n",
    "\n",
    "# NaN 값 제거\n",
    "data = data.dropna()\n",
    "\n",
    "# 특징 및 타겟 설정\n",
    "features = ['AP', 'HUM', 'TEMP', 'WS', 'WD', 'RF']\n",
    "targets_tomorrow = [\n",
    "    'AP_tomorrow', 'TEMP_tomorrow', 'HUM_tomorrow', \n",
    "    'WS_tomorrow', 'WD_tomorrow', 'RF_tomorrow'\n",
    "]\n",
    "targets_day_after = [\n",
    "    'AP_day_after', 'TEMP_day_after', 'HUM_day_after', \n",
    "    'WS_day_after', 'WD_day_after', 'RF_day_after'\n",
    "]\n",
    "\n",
    "X = data[features]\n",
    "y_tomorrow = data[targets_tomorrow]\n",
    "y_day_after = data[targets_day_after]\n",
    "\n",
    "# 데이터 분리\n",
    "X_train, X_test, y_train_tomorrow, y_test_tomorrow = train_test_split(X, y_tomorrow, test_size=0.2, random_state=42)\n",
    "_, _, y_train_day_after, y_test_day_after = train_test_split(X, y_day_after, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 초기화 및 학습\n",
    "model_tomorrow = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "model_day_after = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "\n",
    "model_tomorrow.fit(X_train, y_train_tomorrow)\n",
    "model_day_after.fit(X_train, y_train_day_after)\n",
    "\n",
    "# 예측\n",
    "latest_data = X.iloc[-1:]  # 가장 최근 데이터를 기준으로 예측\n",
    "predicted_tomorrow = model_tomorrow.predict(latest_data)\n",
    "predicted_day_after = model_day_after.predict(latest_data)\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(\"내일 예측:\")\n",
    "print(f\"기압: {predicted_tomorrow[0][0]:.2f} hPa\")\n",
    "print(f\"기온: {predicted_tomorrow[0][1]:.2f} °C\")\n",
    "print(f\"습도: {predicted_tomorrow[0][2]:.2f} %\")\n",
    "print(f\"풍속: {predicted_tomorrow[0][3]:.2f} m/s\")\n",
    "print(f\"풍향: {predicted_tomorrow[0][4]:.2f} °\")\n",
    "print(f\"강수: {predicted_tomorrow[0][5]:.2f} mm\")\n",
    "\n",
    "print(\"\\n모레 예측:\")\n",
    "print(f\"기압: {predicted_day_after[0][0]:.2f} hPa\")\n",
    "print(f\"기온: {predicted_day_after[0][1]:.2f} °C\")\n",
    "print(f\"습도: {predicted_day_after[0][2]:.2f} %\")\n",
    "print(f\"풍속: {predicted_day_after[0][3]:.2f} m/s\")\n",
    "print(f\"풍향: {predicted_day_after[0][4]:.2f} °\")\n",
    "print(f\"강수: {predicted_day_after[0][5]:.2f} mm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bbe6f52f-8279-4a73-8a14-b3a97f94b2e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(2003, \"Can't connect to MySQL server on 'localhost' ([WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다)\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:649\u001b[0m, in \u001b[0;36mConnection.connect\u001b[1;34m(self, sock)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 649\u001b[0m     sock \u001b[38;5;241m=\u001b[39m socket\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    650\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect_timeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    651\u001b[0m     )\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:851\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_errors:\n\u001b[1;32m--> 851\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ExceptionGroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_connection failed\u001b[39m\u001b[38;5;124m\"\u001b[39m, exceptions)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:836\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    835\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m--> 836\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[0;32m    837\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# DB 연결 설정 (본인의 DB 정보로 수정)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m conn \u001b[38;5;241m=\u001b[39m pymysql\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[0;32m     11\u001b[0m     host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m     user\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdbuser\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1234\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m     db\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m     charset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 데이터 가져오기\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:361\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, user, password, host, database, unix_socket, port, charset, collation, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_disabled, ssl_key, ssl_key_password, ssl_verify_cert, ssl_verify_identity, compress, named_pipe, passwd, db)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:716\u001b[0m, in \u001b[0;36mConnection.connect\u001b[1;34m(self, sock)\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[0;32m    715\u001b[0m         \u001b[38;5;28mprint\u001b[39m(exc\u001b[38;5;241m.\u001b[39mtraceback)\n\u001b[1;32m--> 716\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    718\u001b[0m \u001b[38;5;66;03m# If e is neither DatabaseError or IOError, It's a bug.\u001b[39;00m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;66;03m# But raising AssertionError hides original error.\u001b[39;00m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;66;03m# So just reraise it.\u001b[39;00m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mOperationalError\u001b[0m: (2003, \"Can't connect to MySQL server on 'localhost' ([WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다)\")"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# DB 연결 설정 (본인의 DB 정보로 수정)\n",
    "conn = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='dbuser',\n",
    "    password='1234',\n",
    "    db='project',\n",
    "    charset='utf8'\n",
    ")\n",
    "\n",
    "# 데이터 가져오기\n",
    "try:\n",
    "    query = 'SELECT * FROM NAJU_WEATHER_TB'  # 예시: NAJU_WEATHER_TB 테이블에서 데이터 전체를 가져옴\n",
    "    df = pd.read_sql(query, conn)\n",
    "finally:\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 데이터 불러오기\n",
    "file_path = df  # 파일 경로를 실제 파일 경로로 변경\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 시간 정보 처리\n",
    "data['MEAS_DT'] = pd.to_datetime(data['MEAS_DT'])\n",
    "data = data.sort_values('MEAS_DT')\n",
    "\n",
    "# 내일 및 모레 타겟 생성\n",
    "data['AP_tomorrow'] = data['AP'].shift(-24)\n",
    "data['TEMP_tomorrow'] = data['TEMP'].shift(-24)\n",
    "data['HUM_tomorrow'] = data['HUM'].shift(-24)\n",
    "data['WS_tomorrow'] = data['WS'].shift(-24)\n",
    "data['WD_tomorrow'] = data['WD'].shift(-24)\n",
    "data['RF_tomorrow'] = data['RF'].shift(-24)\n",
    "\n",
    "data['AP_day_after'] = data['AP'].shift(-48)\n",
    "data['TEMP_day_after'] = data['TEMP'].shift(-48)\n",
    "data['HUM_day_after'] = data['HUM'].shift(-48)\n",
    "data['WS_day_after'] = data['WS'].shift(-48)\n",
    "data['WD_day_after'] = data['WD'].shift(-48)\n",
    "data['RF_day_after'] = data['RF'].shift(-48)\n",
    "\n",
    "# NaN 값 제거\n",
    "data = data.dropna()\n",
    "\n",
    "# 특징 및 타겟 설정\n",
    "features = ['AP', 'HUM', 'TEMP', 'WS', 'WD', 'RF']\n",
    "targets_tomorrow = [\n",
    "    'AP_tomorrow', 'TEMP_tomorrow', 'HUM_tomorrow', \n",
    "    'WS_tomorrow', 'WD_tomorrow', 'RF_tomorrow'\n",
    "]\n",
    "targets_day_after = [\n",
    "    'AP_day_after', 'TEMP_day_after', 'HUM_day_after', \n",
    "    'WS_day_after', 'WD_day_after', 'RF_day_after'\n",
    "]\n",
    "\n",
    "X = data[features]\n",
    "y_tomorrow = data[targets_tomorrow]\n",
    "y_day_after = data[targets_day_after]\n",
    "\n",
    "# 데이터 분리\n",
    "X_train, X_test, y_train_tomorrow, y_test_tomorrow = train_test_split(X, y_tomorrow, test_size=0.2, random_state=42)\n",
    "_, _, y_train_day_after, y_test_day_after = train_test_split(X, y_day_after, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 초기화 및 학습\n",
    "model_tomorrow = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "model_day_after = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "\n",
    "model_tomorrow.fit(X_train, y_train_tomorrow)\n",
    "model_day_after.fit(X_train, y_train_day_after)\n",
    "\n",
    "# 예측\n",
    "latest_data = X.iloc[-1:]  # 가장 최근 데이터를 기준으로 예측\n",
    "predicted_tomorrow = model_tomorrow.predict(latest_data)\n",
    "predicted_day_after = model_day_after.predict(latest_data)\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(\"내일 예측:\")\n",
    "print(f\"기압: {predicted_tomorrow[0][0]:.2f} hPa\")\n",
    "print(f\"기온: {predicted_tomorrow[0][1]:.2f} °C\")\n",
    "print(f\"습도: {predicted_tomorrow[0][2]:.2f} %\")\n",
    "print(f\"풍속: {predicted_tomorrow[0][3]:.2f} m/s\")\n",
    "print(f\"풍향: {predicted_tomorrow[0][4]:.2f} °\")\n",
    "print(f\"강수: {predicted_tomorrow[0][5]:.2f} mm\")\n",
    "\n",
    "print(\"\\n모레 예측:\")\n",
    "print(f\"기압: {predicted_day_after[0][0]:.2f} hPa\")\n",
    "print(f\"기온: {predicted_day_after[0][1]:.2f} °C\")\n",
    "print(f\"습도: {predicted_day_after[0][2]:.2f} %\")\n",
    "print(f\"풍속: {predicted_day_after[0][3]:.2f} m/s\")\n",
    "print(f\"풍향: {predicted_day_after[0][4]:.2f} °\")\n",
    "print(f\"강수: {predicted_day_after[0][5]:.2f} mm\")\n",
    "\n",
    "# # 데이터 전처리 및 모델링\n",
    "# # RF 열을 숫자형으로 변환 (float으로 변환하고 오류 발생 시 NaN 처리)\n",
    "# df['RF'] = pd.to_numeric(df['RF'], errors='coerce').fillna(0)\n",
    "\n",
    "# # 비 데이터(RF)를 기준으로 이진화 (비가 내렸는지 여부)\n",
    "# df['Rain'] = df['RF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# # 특성과 레이블 선택\n",
    "# X = df[['AP', 'HUM', 'TEMP', 'WS', 'WD']]  # 예측 변수 선택\n",
    "# y = df['Rain']  # 타깃 변수\n",
    "\n",
    "# # 데이터 분할\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 데이터 불균형 해결을 위해 SMOTE 적용\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# # 모델 학습\n",
    "# model = RandomForestClassifier(random_state=42)\n",
    "# model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# # 예측\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # 예측 결과와 실제값을 포함한 결과 DataFrame 생성\n",
    "# results_df = X_test.copy()\n",
    "# results_df['Actual'] = y_test.values\n",
    "# results_df['Predicted'] = y_pred\n",
    "\n",
    "# # 성능 평가\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# # 결과 DataFrame 출력 (원하는 경우 CSV로 저장)\n",
    "# print(results_df.head())  # 결과 미리보기\n",
    "# # results_df.to_csv(\"rain_prediction_results.csv\", index=False)  # CSV 파일로 저장 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a000bb03-11cf-4057-8c49-0544cf24cc15",
   "metadata": {},
   "source": [
    "결과에 대한 의미를 간단히 설명드리면 다음과 같습니다.\n",
    "\n",
    "성능 평가 지표\n",
    "Precision (정밀도): 모델이 '비가 올 것'이라고 예측한 경우 중 실제로 비가 내린 경우의 비율입니다.\n",
    "\n",
    "0 (비가 안 옴): 99%\n",
    "1 (비가 옴): 52%\n",
    "\n",
    "Recall (재현율): 실제 비가 내린 경우 중에서 모델이 '비가 올 것'이라고 올바르게 예측한 비율입니다.\n",
    "\n",
    "0 (비가 안 옴): 98%\n",
    "1 (비가 옴): 71%\n",
    "F1-Score: Precision과 Recall의 조화 평균으로, 두 지표를 모두 고려한 성능 척도입니다.\n",
    "\n",
    "0 (비가 안 옴): 0.99\n",
    "1 (비가 옴): 0.60\n",
    "Accuracy (정확도): 전체 데이터 중 모델이 정확하게 예측한 비율로 97.33%의 높은 정확도를 보입니다. 하지만 클래스 1 (비가 옴)의 경우 예측 성능이 낮아 상대적으로 성능이 떨어집니다.\n",
    "\n",
    "데이터의 클래스 불균형\n",
    "0 (비가 안 옴): 583건\n",
    "1 (비가 옴): 17건\n",
    "비가 내리는 경우가 드물어서 모델이 비가 내리지 않는 경우 (0)를 매우 잘 예측하지만, 비가 오는 경우 (1)는 상대적으로 잘 예측하지 못하는 편입니다.\n",
    "\n",
    "예측 결과 예시\n",
    "아래의 표는 각 샘플의 예측 값과 실제 값을 보여줍니다.\n",
    "\n",
    "AP\tHUM\tTEMP\tWS\tWD\tActual\tPredicted\n",
    "1029.9\t51\t0.3\t3.3\t13.7\t0\t0\n",
    "1024.1\t93\t-4.1\t0.7\t351.3\t0\t0\n",
    "1026.9\t88\t-8\t0.2\t0\t0\t0\n",
    "1013.3\t76\t10\t0.8\t104.1\t0\t0\n",
    "1031.5\t85\t-7\t1.9\t40.3\t0\t0\n",
    "Actual: 실제로 비가 내린 여부 (1이면 비가 옴, 0이면 비가 안 옴)\n",
    "Predicted: 모델이 예측한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bef850e-11ea-491b-93ca-c5b6cfdf4c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DATA_ID      AP  HUM  TEMP   WS     WD   RF  Rain\n",
      "0            1  1024.3   99   8.5  0.3      0  0.0     0\n",
      "1            2  1024.3   99   8.3  0.5   11.8  0.0     0\n",
      "2            3  1023.8  100   8.6  0.7   48.7  0.0     0\n",
      "3            4  1023.7  100   9.3  1.7   46.8  0.0     0\n",
      "4            5  1023.4  100   8.7  1.1   79.8  0.0     0\n",
      "...        ...     ...  ...   ...  ...    ...  ...   ...\n",
      "25470    26280  1021.5   95  13.6    0      0  0.0     0\n",
      "25471    26281    1022   94    14  1.6    157  0.0     0\n",
      "25472    26282    1022   95  12.9  1.2  164.3  0.0     0\n",
      "25473    26283  1021.9   98  11.9  0.7  174.9  0.0     0\n",
      "25474    26284  1022.1   98  10.1    0      0  0.0     0\n",
      "\n",
      "[25475 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df.drop(columns=['MEAS_DT', 'REG_ID', 'REG_DT'])\n",
    "print(filtered_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57fc9b2a-7b11-47fd-a3b3-527d78e6e481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rain\n",
      "0    23963\n",
      "1     1512\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(filtered_df['Rain'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57a7c18c-e4da-4e5e-b4b2-a37919d96391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DATA_ID      AP  HUM  TEMP   WS     WD   RF  Rain\n",
      "0            1  1024.3   99   8.5  0.3      0  0.0     0\n",
      "1            2  1024.3   99   8.3  0.5   11.8  0.0     0\n",
      "2            3  1023.8  100   8.6  0.7   48.7  0.0     0\n",
      "3            4  1023.7  100   9.3  1.7   46.8  0.0     0\n",
      "4            5  1023.4  100   8.7  1.1   79.8  0.0     0\n",
      "...        ...     ...  ...   ...  ...    ...  ...   ...\n",
      "25470    26280  1021.5   95  13.6    0      0  0.0     0\n",
      "25471    26281    1022   94    14  1.6    157  0.0     0\n",
      "25472    26282    1022   95  12.9  1.2  164.3  0.0     0\n",
      "25473    26283  1021.9   98  11.9  0.7  174.9  0.0     0\n",
      "25474    26284  1022.1   98  10.1    0      0  0.0     0\n",
      "\n",
      "[23963 rows x 8 columns]\n",
      "       DATA_ID      AP HUM  TEMP   WS     WD   RF  Rain\n",
      "175        176  1011.1  93  14.3  1.9  274.8  5.5     1\n",
      "176        177  1012.7  92  12.7  3.6  283.4  4.5     1\n",
      "177        178  1014.5  92  11.4  3.3  285.9  3.5     1\n",
      "178        179  1015.4  90  10.4  4.6  283.6  2.5     1\n",
      "179        180  1015.2  89  10.1  2.6  290.3  3.5     1\n",
      "...        ...     ...  ..   ...  ...    ...  ...   ...\n",
      "25427    26237  1012.5  98  14.5  2.2    0.6  2.0     1\n",
      "25428    26238    1013  98  14.6  1.9   34.5  1.0     1\n",
      "25429    26239  1012.6  98  14.5  2.4    9.8  3.0     1\n",
      "25430    26240  1012.5  98  14.7    3  347.3  4.0     1\n",
      "25431    26241  1011.9  98  14.5  2.6   28.7  3.5     1\n",
      "\n",
      "[1512 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Rain이 0인 데이터\n",
    "print(filtered_df[filtered_df['Rain'] == 0])\n",
    "\n",
    "# Rain이 1인 데이터\n",
    "print(filtered_df[filtered_df['Rain'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b65a6760-0807-4840-a67f-194f24f16261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      4792\n",
      "           1       0.45      0.49      0.47       303\n",
      "\n",
      "    accuracy                           0.93      5095\n",
      "   macro avg       0.71      0.73      0.72      5095\n",
      "weighted avg       0.94      0.93      0.94      5095\n",
      "\n",
      "Accuracy: 0.9338567222767419\n",
      "           AP HUM  TEMP   WS     WD  Actual  Predicted\n",
      "7745   1014.1  70    23  1.6   41.2       0          0\n",
      "13523  1010.5  98  20.8  0.1      0       0          0\n",
      "16670  1023.9  88  14.1  0.5  285.4       0          0\n",
      "18340  1027.9  77   0.4  4.8  329.8       0          0\n",
      "2734   1024.1  67   0.7  1.7   53.2       0          0\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 및 모델링\n",
    "# RF 열을 숫자형으로 변환 (float으로 변환하고 오류 발생 시 NaN 처리)\n",
    "df['RF'] = pd.to_numeric(df['RF'], errors='coerce').fillna(0)\n",
    "\n",
    "# 비 데이터(RF)를 기준으로 이진화 (비가 내렸는지 여부)\n",
    "df['Rain'] = df['RF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# 특성과 레이블 선택\n",
    "X = df[['AP', 'HUM', 'TEMP', 'WS', 'WD']]  # 예측 변수 선택\n",
    "y = df['Rain']  # 타깃 변수\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 불균형 해결을 위해 SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 모델 학습\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 예측 결과와 실제값을 포함한 결과 DataFrame 생성\n",
    "results_df = X_test.copy()\n",
    "results_df['Actual'] = y_test.values\n",
    "results_df['Predicted'] = y_pred\n",
    "\n",
    "# 성능 평가\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# 결과 DataFrame 출력 (원하는 경우 CSV로 저장)\n",
    "print(results_df.head())  # 결과 미리보기\n",
    "# results_df.to_csv(\"rain_prediction_results.csv\", index=False)  # CSV 파일로 저장 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d337e2a-57b4-4cf6-8860-e1bc58bd5ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "기압 (AP):  100\n",
      "습도 (HUM):  100\n",
      "온도 (TEMP):  100\n",
      "풍속 (WS):  100\n",
      "풍향 (WD):  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 결과: 비가 오는 날입니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 사용자로부터 과거 특정 날짜의 날씨 데이터 입력\n",
    "ap = float(input(\"기압 (AP): \"))\n",
    "hum = float(input(\"습도 (HUM): \"))\n",
    "temp = float(input(\"온도 (TEMP): \"))\n",
    "ws = float(input(\"풍속 (WS): \"))\n",
    "wd = float(input(\"풍향 (WD): \"))\n",
    "\n",
    "# 입력받은 값을 데이터프레임으로 변환\n",
    "past_day_data = {\n",
    "    'AP': [ap],\n",
    "    'HUM': [hum],\n",
    "    'TEMP': [temp],\n",
    "    'WS': [ws],\n",
    "    'WD': [wd]\n",
    "}\n",
    "past_day_df = pd.DataFrame(past_day_data)\n",
    "\n",
    "# 예측 수행\n",
    "predicted_rain = model.predict(past_day_df)\n",
    "\n",
    "# 예측 결과 출력\n",
    "if predicted_rain[0] == 1:\n",
    "    print(\"예측 결과: 비가 오는 날입니다.\")\n",
    "else:\n",
    "    print(\"예측 결과: 비가 오지 않는 날입니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c044778d-3b1b-4b5f-b14d-da7f4066cf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "기압 (AP):  1000\n",
      "습도 (HUM):  60\n",
      "온도 (TEMP):  20\n",
      "풍속 (WS):  3.4\n",
      "풍향 (WD):  100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 결과: 비가 오지 않는 날입니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class WeatherPredictor:\n",
    "    def __init__(self, model):\n",
    "        # 모델을 초기화합니다.\n",
    "        self.model = model\n",
    "\n",
    "    def get_input_data(self):\n",
    "        # 사용자 입력을 받아 데이터프레임으로 변환합니다.\n",
    "        ap = float(input(\"기압 (AP): \"))\n",
    "        hum = float(input(\"습도 (HUM): \"))\n",
    "        temp = float(input(\"온도 (TEMP): \"))\n",
    "        ws = float(input(\"풍속 (WS): \"))\n",
    "        wd = float(input(\"풍향 (WD): \"))\n",
    "        \n",
    "        past_day_data = {\n",
    "            'AP': [ap],\n",
    "            'HUM': [hum],\n",
    "            'TEMP': [temp],\n",
    "            'WS': [ws],\n",
    "            'WD': [wd]\n",
    "        }\n",
    "        return pd.DataFrame(past_day_data)\n",
    "\n",
    "    def predict_rain(self, input_data):\n",
    "        # 입력 데이터를 기반으로 비가 오는지 예측합니다.\n",
    "        predicted_rain = self.model.predict(input_data)\n",
    "        \n",
    "        # 예측 결과를 반환합니다.\n",
    "        return predicted_rain[0]\n",
    "\n",
    "    def display_prediction(self, prediction):\n",
    "        # 예측 결과를 출력합니다.\n",
    "        if prediction == 1:\n",
    "            print(\"예측 결과: 비가 오는 날입니다.\")\n",
    "        else:\n",
    "            print(\"예측 결과: 비가 오지 않는 날입니다.\")\n",
    "\n",
    "# 사용 예시\n",
    "# model = ... # 사전에 훈련된 모델을 불러와야 합니다.\n",
    "weather_predictor = WeatherPredictor(model)\n",
    "\n",
    "# 데이터 입력\n",
    "input_data = weather_predictor.get_input_data()\n",
    "\n",
    "# 예측 수행\n",
    "prediction = weather_predictor.predict_rain(input_data)\n",
    "\n",
    "# 결과 출력\n",
    "weather_predictor.display_prediction(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8d309c6-01d4-43d4-844b-b61e8a4abbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Balanced Class Weight\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      4792\n",
      "           1       0.45      0.49      0.47       303\n",
      "\n",
      "    accuracy                           0.93      5095\n",
      "   macro avg       0.71      0.73      0.72      5095\n",
      "weighted avg       0.94      0.93      0.94      5095\n",
      "\n",
      "Accuracy: 0.9338567222767419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터 불균형 해결을 위해 SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# RandomForest 모델에 class_weight 옵션 적용\n",
    "rf_model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "rf_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 예측\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "print(\"Random Forest with Balanced Class Weight\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "101db8bd-0e5a-4ed5-98bf-f7a9a2ac7369",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# GridSearchCV로 최적의 하이퍼파라미터 찾기\u001b[39;00m\n\u001b[0;32m     10\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m), \n\u001b[0;32m     11\u001b[0m                            param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train_res, y_train_res)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 최적의 모델로 예측 수행\u001b[39;00m\n\u001b[0;32m     15\u001b[0m best_rf_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 튜닝을 위한 파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# GridSearchCV로 최적의 하이퍼파라미터 찾기\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42, class_weight='balanced'), \n",
    "                           param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 최적의 모델로 예측 수행\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred_best_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "print(\"Best Random Forest Model after Hyperparameter Tuning\")\n",
    "print(classification_report(y_test, y_pred_best_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbe0f242-a9ba-4555-8389-b1d187d3ee52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1591/1591 [==============================] - 10s 6ms/step - loss: 0.0047\n",
      "Epoch 2/50\n",
      "1591/1591 [==============================] - 9s 5ms/step - loss: 3.4696e-04\n",
      "Epoch 3/50\n",
      "1591/1591 [==============================] - 9s 5ms/step - loss: 2.9646e-04\n",
      "Epoch 4/50\n",
      "1591/1591 [==============================] - 9s 5ms/step - loss: 2.8505e-04\n",
      "Epoch 5/50\n",
      "1591/1591 [==============================] - 9s 5ms/step - loss: 2.7724e-04\n",
      "Epoch 6/50\n",
      "1591/1591 [==============================] - 9s 5ms/step - loss: 2.7415e-04\n",
      "Epoch 7/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.6536e-04\n",
      "Epoch 8/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.7713e-04\n",
      "Epoch 9/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.6359e-04\n",
      "Epoch 10/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.6270e-04\n",
      "Epoch 11/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.5835e-04\n",
      "Epoch 12/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.5540e-04\n",
      "Epoch 13/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.5039e-04\n",
      "Epoch 14/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.4545e-04\n",
      "Epoch 15/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.4363e-04\n",
      "Epoch 16/50\n",
      "1591/1591 [==============================] - 11s 7ms/step - loss: 2.4370e-04\n",
      "Epoch 17/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.4040e-04\n",
      "Epoch 18/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.3731e-04\n",
      "Epoch 19/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.3742e-04\n",
      "Epoch 20/50\n",
      "1591/1591 [==============================] - 10s 6ms/step - loss: 2.3629e-04\n",
      "Epoch 21/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.3796e-04\n",
      "Epoch 22/50\n",
      "1591/1591 [==============================] - 10s 6ms/step - loss: 2.3217e-04\n",
      "Epoch 23/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.3750e-04\n",
      "Epoch 24/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.3053e-04\n",
      "Epoch 25/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2965e-04\n",
      "Epoch 26/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2898e-04\n",
      "Epoch 27/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.3011e-04\n",
      "Epoch 28/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2940e-04\n",
      "Epoch 29/50\n",
      "1591/1591 [==============================] - 9s 6ms/step - loss: 2.2722e-04\n",
      "Epoch 30/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2847e-04\n",
      "Epoch 31/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2636e-04\n",
      "Epoch 32/50\n",
      "1591/1591 [==============================] - 9s 5ms/step - loss: 2.2585e-04\n",
      "Epoch 33/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2827e-04\n",
      "Epoch 34/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2688e-04\n",
      "Epoch 35/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2674e-04\n",
      "Epoch 36/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2606e-04\n",
      "Epoch 37/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2580e-04\n",
      "Epoch 38/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2433e-04\n",
      "Epoch 39/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2278e-04\n",
      "Epoch 40/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2528e-04\n",
      "Epoch 41/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2402e-04\n",
      "Epoch 42/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2176e-04\n",
      "Epoch 43/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2151e-04\n",
      "Epoch 44/50\n",
      "1591/1591 [==============================] - 9s 5ms/step - loss: 2.2020e-04\n",
      "Epoch 45/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2151e-04\n",
      "Epoch 46/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.2213e-04\n",
      "Epoch 47/50\n",
      "1591/1591 [==============================] - 10s 6ms/step - loss: 2.2258e-04\n",
      "Epoch 48/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.1997e-04\n",
      "Epoch 49/50\n",
      "1591/1591 [==============================] - 9s 5ms/step - loss: 2.1977e-04\n",
      "Epoch 50/50\n",
      "1591/1591 [==============================] - 8s 5ms/step - loss: 2.1997e-04\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "내일 예상 온도: 11.308805\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "temp_scaled = scaler.fit_transform(df[['TEMP']].values)\n",
    "\n",
    "# 시계열 데이터 준비 (LSTM 입력에 맞게 변환)\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 30  # 최근 30일의 데이터를 사용\n",
    "X, y = create_sequences(temp_scaled, seq_length)\n",
    "\n",
    "# 훈련 및 테스트 분할\n",
    "X_train, X_test = X[:-1], X[-1:]\n",
    "y_train, y_test = y[:-1], y[-1:]\n",
    "\n",
    "# LSTM 모델 생성\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)\n",
    "\n",
    "# 내일 기온 예측\n",
    "tomorrow_temperature_scaled = model.predict(X_test)\n",
    "tomorrow_temperature = scaler.inverse_transform(tomorrow_temperature_scaled)\n",
    "print(\"내일 예상 온도:\", tomorrow_temperature[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "daf0d099-1a13-498f-bc9b-23111af381fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model.save(\"temperature_prediction_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fae77f9-1c4b-46d4-9ffd-a223c8a6e7c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb0 in position 43: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 모델 불러오기\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature_prediction_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 내일 기온 예측 (불러온 모델 사용)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m tomorrow_temperature_scaled \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\saving\\saving_api.py:212\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    205\u001b[0m         filepath,\n\u001b[0;32m    206\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    208\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    213\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    214\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:703\u001b[0m, in \u001b[0;36mis_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether the path is a directory or not.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;124;03m  True, if the path is a directory; False otherwise\u001b[39;00m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 703\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _pywrap_file_io\u001b[38;5;241m.\u001b[39mIsDirectory(compat\u001b[38;5;241m.\u001b[39mpath_to_bytes(path))\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError:\n\u001b[0;32m    705\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb0 in position 43: invalid start byte"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 모델 불러오기\n",
    "loaded_model = load_model(\"temperature_prediction_model.h5\")\n",
    "\n",
    "# 내일 기온 예측 (불러온 모델 사용)\n",
    "tomorrow_temperature_scaled = loaded_model.predict(X_test)\n",
    "tomorrow_temperature = scaler.inverse_transform(tomorrow_temperature_scaled)\n",
    "print(\"내일 예상 온도 (불러온 모델):\", tomorrow_temperature[0][0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
